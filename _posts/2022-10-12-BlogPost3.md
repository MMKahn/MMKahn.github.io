# Project 2

The beginning of the project was a little daunting as I was the first listed group member and therefore the one to create the repo.  I was also weary as we had discussed vignettes in class in previous lectures, but I had not yet used one, let alone created one.  However, after learning my lesson from our first project, I began working on Project 2 two weeks before the due date to allow space for any trial and error.  It was also nice to have access to our Git and GitHub lecture for guidance, which alleviated any issues.  Similar to that lecture, after adding Bennett as a collaborator we were both able to successfully test pulling, making commits, and pushing files to GitHub from RStudio to get the ball rolling.  

From there I started exploring the available API’s online and in RStudio.  After looking them over, Bennett and I decided to use the beer data for our project.  To plan our endpoints, I created the R Markdown file for the project and read in the list of breweries from the API.  We decided to create our functions for contacting the API (`Get_OB_DataFrame()` and `Get_OB_Random()`)  using the `paste0()` function to modify and compile the URL within the `GET()` function instead of making separate functions for each endpoint and combining them with a wrapper function.  Programming the custom functions this way produced more concise, readable code. 

One of the issues we had in choosing the beer data for our project was the lack of numerical data to use in quantitative analysis. We only had the latitude and longitude coordinates for each brewery.  For this reason, I had to get a bit creative when choosing what data to pull from the API using our new functions. I chose to pull California brewery data (`CA_Brew`) since the shape and regional boundaries of the state made it friendly to work with both latitude and longitude data.  I also chose to pull random brewery data from the entirety of the United States (`USA_Brew`), Ireland, and England (`IreEng_Brew`) hoping to get significant findings about brewery preferences by region using coordinate data.  Overall, I believe the exploratory data analysis was able to produce meaningful results, especially when using the new `regions` variables I created for California and USA data sets as fills for the plots created for quantitative analysis.  I was not surprised to find that microbreweries were the most prevalent type of brewery in all three data sets, as craft beer is “all the rage” currently.  I did find it interesting though that, according to the 50 random breweries in the `USA_Brew` data set, most breweries in the United States are located in northern states instead of southern states.

We hit another large bump in the road while rounding the last corner to the finish line.  Once we were satisfied with our work and committed our final touches, I made the repo public and tried to access our rendered github pages repo.  Everything looked fine, except all the images for our plots were missing. I thought something might be wrong with the code in our .R file that creates the README.md file.  As mentioned above, this project was my first attempt creating a vignette and using `github_document` so there was a steep learning curve.  I wasted hours trying to solve our plot rendering issue by adjusting code within the R Script and in the R Markdown YAML (mostly making changes to the output section).  Thankfully another classmate had posted about a similar issue on the course Moodle discussion board, so I discovered the solution to our plot problem was that we had failed to push the README_files/figure-gfm to GitHub as well.  In the future I will be sure to just push everything up to the repo and completely alleviate this problem.

Overall this project was a great learning experience. As with Project 1, there was a lot of trial and error – many more hours toiling over the keyboard than anticipated.  Although I get frustrated during the process, making mistakes (when setting up the repo, rendering the document, deciding the best coding formats for functions, and choosing the most useful data) strengthen by programming skills and help me become a better editor.  It was very nice being able to work with someone during this project to bounce ideas off of and help each other through these issues and mistakes.  I was lucky to have such a wonderful partner in Bennett.  For future projects partner or group projects, I will definitely set up a better mode of communication, however, as Bennett and I mostly used email which wasn’t as conducive for flowing conversation.  Email worked fine for us since we started the project early enough to have the luxury of response time delays especially during the beginning days when we were feeling out the nuts and bolts of the project.  Google Chat or some other messaging app may be more beneficial in the future.

Here is a link to our [rendered github pages repo for Project 2](https://mmkahn.github.io/Project2/)  and our [regular repo](https://github.com/MMKahn/Project2) for your review.
