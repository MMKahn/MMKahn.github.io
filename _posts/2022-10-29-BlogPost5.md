# Blog Post 4

**Write a brief discussion of how you would plan to determine variables to use in a regression model.  What variable selection techniques do you prefer and why?**

Variable selection is arguably the hardest part of building a regression model as we want to find the “best” subset of predictors (JHBSPH, n.d.: 124; Ratner, 2010: 65). Choosing the wrong subset can cause bias in coefficients and p‐values, as well as produce invalid nominal confidence levels (Heinze et al., 2018).  Redundant and irrelevant predictors should be removed and others transformed or re-expressed to fulfill the simplicity aspect of Occam’s Razor, avoid bias and wasting degrees of freedom, prevent collinearity, save money, induce symmetric distribution, and be accurate, stable, and interpretable (JHBSPH, n.d.: 124, Ratner, 2010: 68, 70). As a newcomer to the programming field, variable selection is particularly difficult, but is made easier by having a plan of attack.

Background knowledge and Exploratory Data Analysis (EDA) have been discussed not only in these articles but has been stressed many times in previous lectures and assignments, making them two of my preferred variable selection techniques. Heinze even goes as far as to refer to the acquisition of background knowledge as the golden rule (Heinze et al., 2018). It is important to have statisticians working with the non-statistician content experts in order to create the global model that will be used in techniques down the line.  Background on the data and additional information from your team or leadership about intended outcomes are vital to directing the analysis, so communication is key (Massa-Anthony, 2021). This material is easily obtainable while taking this course as it is usually provided by the instructor, but in a future position this will require more initiative from myself as a data scientist.  

Ratner, echoing the principle of Occam’s Razor, believes simplicity is the golden rule for variable selection, a common characteristic of exploratory data analysis (EDA) (Ratner, 2010: 71). It is essential to conduct “the highly regarded yet often-discarded” EDA to investigate and summarize data sets for a comprehensive understanding of the variables’ patterns and relationships toward one another (Ratner, 2010: 66). The main goal of EDA is to gather important information about the data set – missing data; distribution of data; correlated features; “sticky data characteristics” such as gaps, clumps, and outliers; need for variable transformation or re-expression – before making any assumptions or determining the appropriate statistical techniques for data analysis (Ratner, 2010: 66; Massa-Anthony, 2021; IBM, 2020). It is important to exclude any outliers and perform transformations or re-expressions before moving on to any traditional variable selection techniques as they will inflate prediction errors (JHBSPH, n.d.: 124; Ratner, 2010: 69). I prefer the EDA since it strengthens the traditional variable selection methodology as no other method can achieve transformations or theoretical construction of new variables based on the original variables (Ratner, 2010: 66).  I particularly like that EDA is flexible and universal as it is not a set list of procedures like traditional variable selection methodology, instead utilizing the analyst’s keen intuition to let data guide the analysis (Ratner, 2010: 71, 73).  

Statistical tests, including the most popular criteria used in practical variable selection modeling problems – hypothesis tests – are part of this traditional variable selection methodology along with statistical criteria and stopping rules (Heinze et al., 2018; Ratner, 2010: 66). We have already covered t-tests in this course, so I would feel comfortable executing this approach. Although I am not as familiar with other methods such as the R-squared, adjusted R-squared, Mallows’ Cp and MSE used for analyzing statistical criteria, these methods would be beneficial to variable selection (Ratner, 2010: 66). Average MSE of prediction makes a good criterion, and for Mallows’ Cp I will want models with small p and Cp around or less than p (JHBSPH, n.d.: 129 -130). I would most likely prefer not to use R-squared by itself as it will _always_ choose the largest possible model, which may be desirable in some situations but is not ideal overall when finding the best fit (JHBSPH, n.d.: 129).

There were many types of traditional variable selection techniques with statistical stopping rules discussed in the readings. While forward selection (FS), backward elimination (BE), stepwise forward selection, and stepwise backward selection are all very similar to one another, I would personally prefer to use BE over FS, especially when dealing with collinearity, because it starts with the global model, which carries the assumption of being unbiased (Heinze et al., 2018). While I do not have any personal experience with the procedure yet, in certain situations important predictors should not be missed, augmented backward elimination (ABE) could result in larger, less biased models than BE with a better fitting MSE of regression coefficients (Heinze et al., 2018).  Additionally, I would probably not prefer to use stepwise selection as it produces narrow confidence limits and does not play nice in the presence of redundant predictors (Ratner, 2010: 67).

When it comes to criterion-based or best subset procedures such as Akaike Information Criterion (AIC) and the Bayes Information Criterion (BIC), both have drawbacks. Since the penalty factor of BIC is larger than that of AIC, BIC will penalize larger models more heavily and select smaller models (Heinze et al., 2018; JHBSPH, n.d.: 128). While simplicity is important, underfitting a model to the point where it is too simple to capture the underlying model will lead to high bias and low variance (Lever et al., 2016). Larger models fit better and have smaller residual sum of squares (RSS) (JHBSPH, n.d.: 128). Therefore, I would prefer to use AIC over BIC, although with larger data sets BIC could be used (Heinze et al., 2018). Least angle selection and shrinkage operator (LASSO) penalties create intentionally biased regression coefficients, but can have smaller mean squared error (MSE) than conventional estimates and, especially with small sample sizes, can lower the root mean squared error (RMSE), making it a more preferable technique (Heinze et al., 2018). Overall, criterion-based methods typically involve a wider search than is used in stepwise methods and compare models in a more preferable manner (JHBSPH, n.d.: 133).

When using any of these techniques on hierarchical models,  such as polynomial models and models with interactions, it is important to respect the hierarchy when removing variables (JHBSPH, n.d.: 124) Lower order terms should not be removed before higher order terms in the same variable as it would impact the scale, and joint removal of like terms should be practiced as to not affect the predictor space of the model (JHBSPH, n.d.: 124 -125). Alternatively, there were particular variable selection techniques discussed in the reading that I do not plan to use as well. While univariable variable selection is discussed in the readings, it should be generally avoided and is therefore not one of my preferred variable selection techniques (Heinze et al., 2018). Also, although Heinze goes further in-depth on techniques such as bootstrap resampling and the two‐stage bootstrap procedure to examine model stability, they are not mentioned in the other articles and were only faintly identified in lecture, making them unpreferable to me currently. However as their methodology is beneficial to investigate model uncertainty, I am going to do more research on and practice these procedures.

Citations:

Heinze, G., Wallisch, C., & Dunkler, D. (2018). Variable selection - a review and recommendations for the practicing statistician. _Biometrical Journal, 60_(3), 431–449. https://doi.org/10.1002/bimj.201700067 

IBM Cloud Education. (2020, August 25). _What is exploratory data analysis?_ IBM. Retrieved October 17, 2022, from https://www.ibm.com/cloud/learn/exploratory-data-analysis

Johns Hopkins Bloomberg School of Public Health. (n.d.). _Chapter 10: Variable selection._ Retrieved October 27, 2022, from https://www.biostat.jhsph.edu/~iruczins/teaching/jf/ch10.pdf 

Lever, J., Krzywinski, M., & Altman, N. (2016). Model selection and overfitting. _Nature Methods, 13_(9), 703–704. https://doi.org/10.1038/nmeth.3968 

Massa-Anthony, C. (2021, April 28). _A five-step guide for conducting Exploratory Data Analysis._ Shopify. Retrieved October 17, 2022, from https://shopify.engineering/conducting-exploratory-data-analysis

Ratner, B. (2010). Variable selection methods in regression: Ignorable problem, outing notable solution. _Journal of Targeting, Measurement and Analysis for Marketing, 18_(1), 65–75. https://doi.org/10.1057/jt.2009.26 
