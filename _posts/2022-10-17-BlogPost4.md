# Blog Post 3

**Write up the strategy you use for EDA. What is your overall goal when doing an EDA? What methods do you think are important? What things do you try to look for?**

At this point in the semester, my ST558 classmates and I have built a strong foundation for running basic data analysis in R Studio.  Before tackling more in-depth statistical tools and techniques, it is essential to conduct this Exploratory Data Analysis (EDA) to investigate and summarize data sets for a comprehensive understanding of the variables’ patterns and relationships toward one another. The main goal of EDA is to gather important information about the data set; such as missing data, distribution of data, correlated features, and outliers; prior to making any assumptions or determining the appropriate statistical techniques for data analysis (Massa-Anthony, 2021; IBM, 2020).  I particularly like that EDA is not a set list of procedures, but rather “a philosophy as to how we dissect a data set; what we look for; how we look; and how we interpret” (NIST, n.d.).  Since EDA is often performed using visualization methods, the observed phenomena can uncover underlying structure and anomalies, as well as test hypothesis and assumptions (Massa-Anthony, 2021; Wikimedia, 2022; NIST, n.d.).

Even before starting an EDA, it is vital to have some background on the data and information from your team or leadership about intended outcomes to focus the analysis (Massa-Anthony, 2021). This material is easily obtainable while taking a course as it is usually provided by the instructor, but in a future position this may require more initiative from the data scientist.  Being familiar with the data set’s observations and variables will always be important as well. This is the very first step I take in interpreting the data: using the `str()` structure function to examine the internal structure of the data set; and using the `head()` function to show the first 6 observations of the data set (by default) to examine its features.  When exploring the variables, I take note if they are categorical or quantitative.  In the future, I will go even further to separate the quantitative variables into discrete and continuous data as suggested by Cody Massa-Anthony since applicable visualizations and statistical methods vary amongst feature types.

I then check the data set for any missing data. In the past, I mostly did this because missing data can cause issues in later analysis and plotting if unaddressed. However, after reading Cody Massa-Anthony’s article on A five-step guide for conducting Exploratory Data Analysis, I saw that there are many other significant reasons and methods for assessing missing data. It is important to determine why the data is missing, the implications of its absence, and if “missing data is a feature in its own right and should be treated as such” (Massa-Anthony, 2021).  The bar plot Massa-Anthony created to show the percentage of missing values per feature is a technique I will be using in the future as I find it extremely beneficial for data interpretation and elimination of bias.  

My next EDA strategies are to observe and analyze the distribution of and correlations in my data.  Possibly due to the original order of our lectures, I prefer to examine numerical summaries before graphical summaries.  Typically I use the `table()` function to create contingency tables for categorical data and functions to examine measures of center and spread for quantitative data such as `summary()`, `var()`, and `sd()`, although there are many others to use.  Variation and typical values are important descriptive statistics used to understand the data. For example, if the values for mean and median are far apart, the values are not normally distributed and the median show be examined as a better representation for the center, typical value. I also calculate the correlation between variables using the `cor()` function. The numbers I receive from these numerical summaries should be reflected in the visualizations from my graphic summaries. 

When graphing summaries, I create side-by-side bar plots, line plots, histograms, box plots, and scatter plots to visualize relationships between variables using the `ggplot2` package (`ggplot()` and `geom_type()`). Graphics are important to EDA as they facilitate the open-minded exploration that is required through “new, often unsuspected, insight into the data” (NIST, n.d.). The comparative nature of each plot type speaks directly to their worth and appeal for EDA. Previously calculated measures of spread and center are illustrated and easily assessed via the shape of the data (bar plots, line plots, and histograms), correlation of the variables (box plots and scatter plots), and spotting outliers (mostly box plots, but also scatter plots). 

All of these calculations and observations can be used create hypothesis about the data.  The Massa-Anthony article also mentioned Probability Density Functions (PDFs) for continuous features and Probability Mass Functions (PMFs) discrete features, which I will use in the future as an additional measure the skewness beside calculations such as mean and median, as well as the box plot.  Also in addition to the box plots using continuous data, I will test the method Massa-Anthony uses to spot outliers by finding observations greater than the 99th percentile or less than the 1st percentile for each feature, and rank them from most to least outliers. Any outliers should be investigated further as they can negatively influence later analysis, but variables with the most outliers should be under the most scrutiny and consideration. For correlation analysis, I usually stick to the `cor()` function and a scatter plot with `geom_smooth()` to add a regression line with method `lm` for a linear model. In the future I will also try the Pearson correlation matrix for data sets with many variables, autocorrelation for time series data, and the Pearson chi-square test for categorical variables as suggested by Massa-Anthony.

Overall, EDA is an extremely important aspect and philosophy of data science. Exploratory Data Analysis allows us to dig deeper into the data and reveal underlying “secrets” and relationships (NIST, n.d.).  I find the most significant discoveries in the visualization side of EDA, where my eyes can easily assess vast amounts of data; address any issues therein such as missing, incorrect, or anomalous data; and evaluate relationships and correlations amongst variables.  While I believe the strategies we learned in lecture for numerical and graphical summaries are helpful, the reading from this week have provided me with many great ways to improve my EDA strategies.

Citations:
IBM Cloud Education. (2020, August 25). _What is exploratory data analysis?_ IBM. Retrieved October 17, 2022, from https://www.ibm.com/cloud/learn/exploratory-data-analysis 
Massa-Anthony, C. (2021, April 28). _A five-step guide for conducting Exploratory Data Analysis._ Shopify. Retrieved October 17, 2022, from https://shopify.engineering/conducting-exploratory-data-analysis 
National Institute of Standards and Technology - US Department of Commerce. (n.d.). _What is EDA?_ Engineering Statistics Handbook. Retrieved October 17, 2022, from https://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm 
Wikimedia Foundation. (2022, September 20). _Exploratory Data Analysis._ Wikipedia. Retrieved October 17, 2022, from https://en.wikipedia.org/wiki/Exploratory_data_analysis 
