# Project 3 Reflection

The online news popularity data used for this project summarized a diverse set of features about articles published by [Mashable](http://www.mashable.com) over a two-year period with the goal of predicting the number of `shares` in social networks - a proxy for popularity.  To achieve this goal, my partner Rachel and I created predictive models for this data set and find which one performed the best. After Rachel created the repo, I did some initial coding to read in the data, write the introduction, subset the data by channel of interest (we chose social media), split the data into a training and test set, and compete my section of the EDA using summary statistics for the shares variable and scatter plots to determine correlation between predictor variables.  I then created a simple linear regression model and a boosted tree model to fit to the training set while Rachel created a multiple regression model and a random forest model.  We compared the performance of the models based on the root-mean-square error (RMSE) calculation. We created functions to determine the best model using the smallest RMSE from the test set. This process was then done across each data channel (lifestyle, entertainment, business, social media, tech, and world) using automated RMarkdown reports.

This project was quite different from the others as it allowed for much more flexibility in the execution of the outputs, which is more realistic to something we’d encounter in the professional world.  This, of course, made the project uniquely difficult compared to our previous projects.  I spent a lot of extra time trying different models and predictors because my performance calculation results were consistently poor.  The RMSE calculations were extremely high, while R-squared calculations were extremely low. Any adjustments I tried to make only slightly changed the calculations, so I thought I was doing something wrong. However, after reaching out to my partner Rachel, she was experiencing the same issues.  In our search for better results, we came to the conclusion that the given variables were simply not strong predictors of `shares`.  As a real data set, it was a teachable moment for us since we’ll have to deal with imperfect data sets where our results will not always be ideal in our future careers.

The most difficult part of this project was without a doubt the automation piece.  Every other section dealt with methods and strategies what we had practiced multiple times in previous assignments. While we did have a lecture on automation in Topic 2 of our course, I had not personally attempted the process before this project – a downfall I regretted very much.  Between learning what should and should not be in the YAML header, how to code and where to place the render function, and debugging error messages, the automation section of this homework took me an entire day to troubleshoot.  Thankfully Dr. Post was able to provide guidance on where our coding was going wrong – specifically using the `get()` function to fix our tibble with no observations issue and using a .R file instead of a .rmd file for the `render` function.  While it was extremely difficult to work out, the process of automation is something that will stick with me since I spent so much time personally researching it.

I think Rachel and I worked very well together, so there isn’t much I would change about the experience.  While I did spend a few too many hours testing different predictors in my models, I believe that was a necessary part of the assignment.  Although the automation section was located at the end of the assignment, I should have reviewed the technique immediately when I read through the instructions. I was aware from the very beginning that it was something I was not as familiar with, but waited until the bridge needed to be crossed to address my lack of understanding.  If I would have gone back to our automation lecture earlier in the process, it would have given me more time to understand how I would need to apply the method in terms of this specific project.  Doing this step sooner would have also allowed me to reach out for help earlier and relieve some of my own stress and anxiety.  Overall, this project was full of learning experiences that will no doubt be beneficial in my final project and future career.

Here is a link to our [rendered github pages repo for Project 3]( https://rlhardy2.github.io/ST-558-Project-3/)  and our [regular repo](https://github.com/rlhardy2/ST-558-Project-3) for your review.
